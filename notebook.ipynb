{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dd90764",
   "metadata": {},
   "source": [
    "____\n",
    "__Universidad de San Andrés__<br/>\n",
    "__Machine Learning__<br/>\n",
    "__Modelado probabilistico de audios de ballenas y estudio de transfer learning__<br/>\n",
    "__Martin Bianchi y Federico Gutman__\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baffab2",
   "metadata": {},
   "source": [
    "### Importamos las librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af96e674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import librosa\n",
    "from IPython.display import Audio, display\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2aa0fa",
   "metadata": {},
   "source": [
    "### NOTAS\n",
    "- ver repo para preprocesar espectrogrma\n",
    "    - ver de reducir el y-lim del spectrograma -> averiguar bien entre que frecuencias se mueven los cantos de ballena\n",
    "- cambiar noise a no right whale\n",
    "- cambiar el idioma a español\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95f75ba",
   "metadata": {},
   "source": [
    "### Definimos algunas variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc552f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 3            # semilla para reproductibilidad\n",
    "SR = 2000           # sampling rate\n",
    "N_FFT = 256         # tamaño de la ventana\n",
    "HOP_LENGTH = 64     # salto entre frames\n",
    "N_MELS = 50         # frequency bins (resolución)\n",
    "MAX_FREQ = 600      # máxima frecuencia para los espectrogramas --ponerlo en 500--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7971bf89",
   "metadata": {},
   "source": [
    "### Cargamos los datos y los visualizamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72587866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(train_path:str, test_path:str, labels_path:str, sampling_rate=SR):\n",
    "    test_files = [f for f in os.listdir(test_path) if f.endswith('.aiff')]\n",
    "    labels_df = pd.read_csv(labels_path)\n",
    "\n",
    "    audio_df = labels_df.copy()\n",
    "    audio_df['filepath'] = audio_df['clip_name'].apply(lambda x: os.path.join(train_path, x))\n",
    "    audio_df['audio'] = audio_df['filepath'].apply(lambda path: librosa.load(path, sr=sampling_rate)[0])\n",
    "\n",
    "    return audio_df, labels_df, test_files\n",
    "\n",
    "def display_random_samples(dataset:pd.DataFrame, sampling_rate=SR):\n",
    "    np.random.seed(SEED)\n",
    "\n",
    "    # SAMPLES\n",
    "    whale_sample = dataset[dataset['label'] == 1].sample(5)['audio']\n",
    "    noise_sample = dataset[dataset['label'] == 0].sample(5)['audio']\n",
    "\n",
    "    # AUDIO\n",
    "    print('right whale call random audio sample')\n",
    "    display(Audio(np.array(whale_sample.iloc[0]), rate=sampling_rate*1.5))\n",
    "    print('\\nno whale random audio sample')\n",
    "    display(Audio(np.array(noise_sample.iloc[0]), rate=sampling_rate*1.5))\n",
    "\n",
    "    # SOUND-WAVE\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(15, 5))\n",
    "\n",
    "    for i in range(5):\n",
    "        axes[0, i].plot(np.array(whale_sample.iloc[i]))\n",
    "        axes[0, i].set_title('Whale')\n",
    "        axes[0, i].set_xticks([])\n",
    "        axes[0, i].set_yticks([])\n",
    "\n",
    "        axes[1, i].plot(np.array(noise_sample.iloc[i]), color='#FF6961')\n",
    "        axes[1, i].set_title('No Whale')\n",
    "        axes[1, i].set_xticks([])\n",
    "        axes[1, i].set_yticks([])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # MULTIPLE SPECTROGRAMS\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "\n",
    "    for i in range(5):\n",
    "        whale_sample_spectrogram = get_melspectrogram(whale_sample.iloc[i])\n",
    "        img0 = librosa.display.specshow(whale_sample_spectrogram, sr=sampling_rate, hop_length=HOP_LENGTH, ax=axes[0, i], x_axis='time', y_axis='hz', cmap='magma', fmax=MAX_FREQ)\n",
    "        axes[0, i].set_title('Whale')\n",
    "        axes[0, i].set_ylim([0, MAX_FREQ])\n",
    "        axes[0, i].set_xticks([])\n",
    "        axes[0, i].set_yticks([])\n",
    "        axes[0, i].set_xlabel('')\n",
    "        axes[0, i].set_ylabel('')\n",
    "\n",
    "        noise_sample_spectrogram = get_melspectrogram(noise_sample.iloc[i])\n",
    "        img1 = librosa.display.specshow(noise_sample_spectrogram, sr=sampling_rate, hop_length=HOP_LENGTH, ax=axes[1, i], x_axis='time', y_axis='hz', cmap='magma', fmax=MAX_FREQ)\n",
    "        axes[1, i].set_title('No Whale')\n",
    "        axes[1, i].set_ylim([0, MAX_FREQ])\n",
    "        axes[1, i].set_xticks([])\n",
    "        axes[1, i].set_yticks([])\n",
    "        axes[1, i].set_xlabel('')\n",
    "        axes[1, i].set_ylabel('')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # TWO SPECTROGRAMS\n",
    "    whale_sample2 = dataset[dataset['label'] == 1].sample(1, random_state=SEED+1)['audio']\n",
    "    noise_sample2 = dataset[dataset['label'] == 0].sample(1, random_state=SEED+1)['audio']\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(7, 3))\n",
    "\n",
    "    whale_sample2_spectrogram = get_melspectrogram(whale_sample2.iloc[0])\n",
    "    img0 = librosa.display.specshow(whale_sample2_spectrogram, sr=sampling_rate, hop_length=HOP_LENGTH, ax=axes[0], x_axis='time', y_axis='hz', cmap='magma', fmax=MAX_FREQ)\n",
    "    axes[0].set_title('Whale')\n",
    "    axes[0].set_ylim([0, MAX_FREQ])\n",
    "    fig.colorbar(img0, ax=axes[0], format=\"%+2.0f dB\")\n",
    "\n",
    "    noise_sample2_spectrogram = get_melspectrogram(noise_sample2.iloc[0])\n",
    "    img1 = librosa.display.specshow(noise_sample2_spectrogram, sr=sampling_rate, hop_length=HOP_LENGTH, ax=axes[1], x_axis='time', y_axis='hz', cmap='magma', fmax=MAX_FREQ)\n",
    "    axes[1].set_title('No Whale')\n",
    "    axes[1].set_ylim([0, MAX_FREQ])\n",
    "    fig.colorbar(img1, ax=axes[1], format=\"%+2.0f dB\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def normalize(dataset:pd.DataFrame, column:str):\n",
    "    dataset[column] = dataset[column].apply(lambda x: x / np.max(np.abs(x)))\n",
    "\n",
    "def get_signal_energy(dataset:pd.DataFrame, column:str):\n",
    "    energy = []\n",
    "    df = dataset.copy()\n",
    "    for x in df[column]:\n",
    "        energy.append(np.sum(np.square(x)))\n",
    "    df['energy'] = energy\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_melspectrogram(sample:pd.DataFrame, sampling_rate=SR, n_fft=N_FFT, hop_length=HOP_LENGTH, n_mels=N_MELS):\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=np.array(sample), sr=sampling_rate, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels, fmax=MAX_FREQ)\n",
    "    mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "    return mel_spectrogram\n",
    "\n",
    "def get_all_mel_spectrograms(audio_df, sampling_rate=SR, n_fft=N_FFT, hop_length=HOP_LENGTH, n_mels=N_MELS):\n",
    "    mel_specs = []\n",
    "    for audio in audio_df['audio']:\n",
    "        mel = get_melspectrogram(audio, sampling_rate, n_fft, hop_length, n_mels)\n",
    "        mel_specs.append(mel.flatten())\n",
    "    return np.array(mel_specs)\n",
    "\n",
    "def show_class_balance(dataset:pd.DataFrame):\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    ax = sns.countplot(\n",
    "        x='label',\n",
    "        data=dataset,\n",
    "        palette={0: '#FF6961', 1: plt.rcParams['axes.prop_cycle'].by_key()['color'][0]},\n",
    "        hue='label',\n",
    "        legend=False\n",
    "    )\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_xticklabels(['Noise', 'Whale'])\n",
    "    ax.legend(['Noise', 'Whale'], title='Class')\n",
    "    plt.show()\n",
    "\n",
    "def extract_time_acoustic_features(dataset:pd.DataFrame):\n",
    "    new_features = []\n",
    "    for audio in dataset['audio']:\n",
    "        audio_np = np.array(audio)\n",
    "        acoustic_features = {\n",
    "            'rms_energy': np.mean(librosa.feature.rms(y=audio_np)),\n",
    "            'zcr': np.mean(librosa.feature.zero_crossing_rate(y=audio_np)),\n",
    "        }\n",
    "        new_features.append(acoustic_features)\n",
    "    features_df = pd.DataFrame(new_features)\n",
    "    return features_df\n",
    "\n",
    "def extract_frequency_acoustic_features(dataset:pd.DataFrame):\n",
    "    new_features = []\n",
    "    for audio in dataset['audio']:\n",
    "        audio_np = np.array(audio)\n",
    "        acoustic_features = {\n",
    "            'spectral_centroid': np.mean(librosa.feature.spectral_centroid(y=audio_np)),\n",
    "            'spectral_bandwidth': np.mean(librosa.feature.spectral_bandwidth(y=audio_np)),\n",
    "            'spectral_rolloff': np.mean(librosa.feature.spectral_rolloff(y=audio_np)),\n",
    "            'spectral_flatness': np.mean(librosa.feature.spectral_flatness(y=audio_np))\n",
    "        }\n",
    "        new_features.append(acoustic_features)\n",
    "    features_df = pd.DataFrame(new_features)\n",
    "    return features_df\n",
    "\n",
    "def extract_acoustic_features(dataset:pd.DataFrame):\n",
    "    time_features = extract_time_acoustic_features(dataset)\n",
    "    frequency_features = extract_frequency_acoustic_features(dataset)\n",
    "\n",
    "    new_df = pd.concat([dataset.reset_index(drop=True), time_features], axis=1)\n",
    "    new_df = pd.concat([new_df.reset_index(drop=True), frequency_features], axis=1)\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "def display_features_boxplots(audio_features_df:pd.DataFrame):\n",
    "    time_features = ['rms_energy', 'zcr']\n",
    "    freq_features = ['spectral_centroid', 'spectral_bandwidth', 'spectral_rolloff', 'spectral_flatness']\n",
    "\n",
    "    # TIME\n",
    "    fig, axes = plt.subplots(1, len(time_features), figsize=(5 * len(time_features), 5))\n",
    "    if len(time_features) == 1:\n",
    "        axes = [axes]\n",
    "    for i, feature in enumerate(time_features):\n",
    "        sns.boxplot(x='label', y=feature, data=audio_features_df, ax=axes[i], showfliers=False)\n",
    "        axes[i].set_title(f'{feature} by Class')\n",
    "        axes[i].set_xlabel('Class')\n",
    "        axes[i].set_xticks([0, 1])\n",
    "        axes[i].set_xticklabels(['Noise', 'Whale'])\n",
    "\n",
    "    plt.suptitle('Time Domain Features by Class')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # FREQUENCY\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "    axes = axes.flatten()\n",
    "    for i, feature in enumerate(freq_features):\n",
    "        sns.boxplot(x='label', y=feature, data=audio_features_df, ax=axes[i], showfliers=False)\n",
    "        axes[i].set_title(f'{feature} by Class')\n",
    "        axes[i].set_xlabel('Class')\n",
    "        axes[i].set_xticks([0, 1])\n",
    "        axes[i].set_xticklabels(['Noise', 'Whale'])\n",
    "\n",
    "    plt.suptitle('Frequency Domain Features by Class')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_pca(dataset:pd.DataFrame, pca_arr):\n",
    "    plt.figure(figsize=(8,6))\n",
    "    scatter = sns.scatterplot(\n",
    "        x=pca_arr[:,0], \n",
    "        y=pca_arr[:,1], \n",
    "        hue=dataset['label'], \n",
    "        palette={0: '#FF6961', 1: '#1f77b4'}\n",
    "    )\n",
    "    plt.title('PCA of Mel Spectrograms')\n",
    "    plt.xlabel('PC 1')\n",
    "    plt.ylabel('PC 2')\n",
    "    # Fix legend labels and colors\n",
    "    handles, _ = scatter.get_legend_handles_labels()\n",
    "    scatter.legend(handles=handles, title='Class', labels=['Noise', 'Whale'])\n",
    "    plt.show()\n",
    "\n",
    "def plot_average_spectrograms(audio_df:pd.DataFrame):\n",
    "    whale_spectrograms = []\n",
    "    noise_spectrograms = []\n",
    "    for audio, label in zip(audio_df['audio'], audio_df['label']):\n",
    "        spectrogram = get_melspectrogram(audio)\n",
    "        if label == 1:\n",
    "            whale_spectrograms.append(spectrogram)\n",
    "        else: \n",
    "            noise_spectrograms.append(spectrogram)\n",
    "    \n",
    "    whale_spectrograms = np.array(whale_spectrograms)\n",
    "    noise_spectrograms = np.array(noise_spectrograms)\n",
    "\n",
    "    whale_average_spectrogram = whale_spectrograms.mean(axis=0)\n",
    "    noise_average_spectrogram = noise_spectrograms.mean(axis=0)\n",
    "    average_differences_spectrogram = whale_average_spectrogram - noise_average_spectrogram\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(10, 3))\n",
    "    img0 = librosa.display.specshow(whale_average_spectrogram, sr=SR, hop_length=HOP_LENGTH, ax=axes[0], x_axis='time', y_axis='hz', cmap='magma', fmax=MAX_FREQ)\n",
    "    axes[0].set_title('Whale Call Average Spectrogram', pad=20)\n",
    "    axes[0].set_ylim([0, MAX_FREQ])\n",
    "    # axes[0].set_xticks([])\n",
    "    # axes[0].set_yticks([])\n",
    "    fig.colorbar(img0, ax=axes[0], format=\"%+2.0f dB\")\n",
    "\n",
    "    img1 = librosa.display.specshow(noise_average_spectrogram, sr=SR, hop_length=HOP_LENGTH, ax=axes[1], x_axis='time', y_axis='hz', cmap='magma', fmax=MAX_FREQ)\n",
    "    axes[1].set_title('No Whale Call Average Spectrogram', pad=20)\n",
    "    axes[1].set_ylim([0, MAX_FREQ])\n",
    "    # axes[1].set_xticks([])\n",
    "    # axes[1].set_yticks([])\n",
    "    fig.colorbar(img1, ax=axes[1], format=\"%+2.0f dB\")\n",
    "\n",
    "    img2 = librosa.display.specshow(average_differences_spectrogram, sr=SR, hop_length=HOP_LENGTH, ax=axes[2], x_axis='time', y_axis='hz', cmap='magma', fmax=MAX_FREQ)\n",
    "    axes[2].set_title('Average Differences Spectrogram', pad=20)\n",
    "    axes[2].set_ylim([0, MAX_FREQ])\n",
    "    # axes[2].set_xticks([])\n",
    "    # axes[2].set_yticks([])\n",
    "    fig.colorbar(img2, ax=axes[2], format=\"%+2.0f dB\")\n",
    "\n",
    "    # 3 subplots -> average spectrogram whale, noise, resto y consigo diferencias\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac9470e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data/whale-detection-challenge/data/train'\n",
    "test_dir = 'data/whale-detection-challenge/data/test'\n",
    "labels_dir = 'data/whale-detection-challenge/data/train.csv'\n",
    "\n",
    "audio_df, labels_df, test_files = load_data(train_dir, test_dir, labels_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87283539",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize(audio_df, 'audio')\n",
    "display_random_samples(audio_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cd1a46",
   "metadata": {},
   "source": [
    "### Hacemos un análisis exploratorio de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6da0280",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_class_balance(audio_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26d3cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_average_spectrograms(audio_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9656f2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features_df = extract_acoustic_features(audio_df)\n",
    "display_features_boxplots(audio_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8c3eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENTO PCA\n",
    "flattened_mel_spectrogram = get_all_mel_spectrograms(audio_df)\n",
    "pca = PCA(n_components=2)\n",
    "spec_pca = pca.fit_transform(flattened_mel_spectrogram)\n",
    "\n",
    "plot_pca(audio_df, spec_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5032c92c",
   "metadata": {},
   "source": [
    "### Arrancamos el modelado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419d7f2a",
   "metadata": {},
   "source": [
    "### Importamos las librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124b53cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import KFold, ParameterGrid, StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, roc_curve, roc_auc_score\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b2fb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_spectrogram(spec, global_min, global_max):\n",
    "    norm_spec = (spec - global_min) / (global_max - global_min + 1e-8)\n",
    "    return norm_spec\n",
    "\n",
    "def denormalize_spectrogram(norm_spec, min_val, max_val):\n",
    "    return norm_spec * (max_val - min_val + 1e-8) + min_val\n",
    "\n",
    "def compute_global_min_max(audio_df):\n",
    "    whale_specs = [get_melspectrogram(audio) for audio, label in zip(audio_df['audio'], audio_df['label']) if label == 1]\n",
    "    global_min = np.min([spec.min() for spec in whale_specs])\n",
    "    global_max = np.max([spec.max() for spec in whale_specs])\n",
    "    return global_min, global_max\n",
    "\n",
    "def get_class_weights(y):\n",
    "    weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "    return torch.tensor(weights, dtype=torch.float32)\n",
    "\n",
    "def get_data_loaders(train_df):\n",
    "    X = get_all_mel_spectrograms(train_df)\n",
    "    y = train_df['label'].values\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=SEED)\n",
    "\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "    X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "    y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=128, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(X_val_tensor, y_val_tensor), batch_size=128)\n",
    "\n",
    "    return train_loader, val_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3189a94",
   "metadata": {},
   "source": [
    "### Creamos las clases y funciones necesarias para los modelos de clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0aa88353",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_layers=[256, 128, 64], output_dim=2):\n",
    "        super(MLP, self).__init__()\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "\n",
    "        for hidden_layer in hidden_layers:\n",
    "            layers.append(nn.Linear(prev_dim, hidden_layer))\n",
    "            layers.append(nn.ReLU())\n",
    "            prev_dim = hidden_layer\n",
    "        layers.append(nn.Linear(prev_dim, output_dim))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def train_model(self, train_loader, val_loader, epochs=50, lr=0.001, weight_decay=1e-5, early_stopping_patience=None):\n",
    "        self.to(self.device)\n",
    "        y_train = train_loader.dataset.tensors[1].cpu().numpy().flatten()\n",
    "        loss_function = nn.CrossEntropyLoss(weight=get_class_weights(y_train).to(self.device))\n",
    "        optimizer = optim.Adam(self.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        best_val_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            self.train()\n",
    "            running_loss = 0.0\n",
    "            for inputs, labels in train_loader:\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self(inputs)\n",
    "                loss = loss_function(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "            avg_train_loss = running_loss / len(train_loader.dataset)\n",
    "            train_losses.append(avg_train_loss)\n",
    "\n",
    "            val_loss, val_acc = self.evaluate(val_loader, return_metrics=True)\n",
    "            val_losses.append(val_loss)\n",
    "\n",
    "            print(f'Epoch {epoch+1}/{epochs} | Train Loss: {avg_train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%')\n",
    "\n",
    "            # Early stopping\n",
    "            if early_stopping_patience is not None:\n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    patience_counter = 0\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    if patience_counter >= early_stopping_patience:\n",
    "                        print(\"Early stopping triggered.\")\n",
    "                        break\n",
    "\n",
    "        return train_losses, val_losses\n",
    "\n",
    "    def evaluate(self, val_loader, return_metrics=False):\n",
    "        self.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        loss_function = nn.CrossEntropyLoss()\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                outputs = self(inputs)\n",
    "                loss = loss_function(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "        accuracy = 100 * correct / total\n",
    "        if return_metrics:\n",
    "            return avg_val_loss, accuracy\n",
    "        print(f'Validation Loss: {avg_val_loss:.4f}, Accuracy: {accuracy:.2f}%')\n",
    "    \n",
    "# ESTO DE ABAJO NO ANDA TODAVIA PERO ES PARA YA TENERLO\n",
    "def MLP_cross_val(train_loader:DataLoader, val_loader:DataLoader, input_dim:int, hidden_layers:list, output_dim:int, epochs:int, lr:list, weight_decay:list, regularization_term:list, early_stopping_patience:list):\n",
    "    best_model = None\n",
    "    best_val_loss = float('inf')\n",
    "    best_params = None\n",
    "    global_min, global_max = compute_global_min_max(train_loader.dataset)\n",
    "    for lr_val in lr:\n",
    "        for wd in weight_decay:\n",
    "            for reg in regularization_term:\n",
    "                model = MLP(input_dim, hidden_layers, output_dim)\n",
    "                model.train(train_loader, val_loader, epochs=epochs, lr=lr_val, weight_decay=wd)\n",
    "\n",
    "                # Evaluate on validation set\n",
    "                val_loss = 0.0\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    for inputs, labels in val_loader:\n",
    "                        inputs, labels = inputs.to(model.device), labels.to(model.device)\n",
    "                        outputs = model(inputs)\n",
    "                        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "                        val_loss += loss.item()\n",
    "\n",
    "                val_loss /= len(val_loader)\n",
    "\n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    best_model = model\n",
    "                    best_params = (lr_val, wd, reg)\n",
    "    print(f'Best Validation Loss: {best_val_loss:.4f} with params: LR={best_params[0]}, WD={best_params[1]}, Reg={best_params[2]}')\n",
    "    return best_model, best_params    \n",
    "\n",
    "def train_random_forest(X_train, y_train, X_val, y_val):\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    preds = rf.predict(X_val)\n",
    "    acc = accuracy_score(y_val, preds)\n",
    "    print(f\"Validation Accuracy (Random Forest): {acc:.4f}\")\n",
    "    return rf\n",
    "\n",
    "def train_gradient_boosting(X_train, y_train, X_val, y_val):\n",
    "    gb = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "    gb.fit(X_train, y_train)\n",
    "    preds = gb.predict(X_val)\n",
    "    acc = accuracy_score(y_val, preds)\n",
    "    print(f\"Validation Accuracy (Gradient Boosting): {acc:.4f}\")\n",
    "    return gb\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db6d377",
   "metadata": {},
   "source": [
    "### Obtenemos los audios de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87161b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_train_df = audio_df[audio_df['clip_name'].str.contains('train')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14da827",
   "metadata": {},
   "source": [
    "### Hacemos validación cruzada alternando entre una loss con pesos y cambiando la máxima frecuencia de los espectrogramas\n",
    "\n",
    "explicar lo de las frecuencias de 500 (standard ballena) - y 600 imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85d0531",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "original_max_freq = MAX_FREQ\n",
    "n_folds = 5\n",
    "patience = 3\n",
    "\n",
    "for max_frequency in [500, 600, 1000]:\n",
    "    print(f'\\n--- MAX_FREQ = {max_frequency} HZ ---')\n",
    "    MAX_FREQ = max_frequency\n",
    "\n",
    "    X = get_all_mel_spectrograms(audio_train_df)\n",
    "    y = audio_train_df['label'].values\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=SEED)\n",
    "\n",
    "    for weighted in [False, True]:\n",
    "        print(f'\\n--- WEIGHTED LOSS = {weighted} ---')\n",
    "        fold_aucs = []\n",
    "        fold_f1s = []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "            print(f'\\nFold {fold+1}/{n_folds}')\n",
    "            X_train, X_val = X[train_idx], X[val_idx]\n",
    "            y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "            X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "            y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "            X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "            y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "            train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=128, shuffle=True)\n",
    "            val_loader = DataLoader(TensorDataset(X_val_tensor, y_val_tensor), batch_size=128)\n",
    "\n",
    "            mlp = MLP(X_train.shape[1]).to(device)\n",
    "            if weighted:\n",
    "                weights = get_class_weights(y_train).to(device)\n",
    "                loss_function = nn.CrossEntropyLoss(weight=weights)\n",
    "            else:\n",
    "                loss_function = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.Adam(mlp.parameters(), lr=1e-3)\n",
    "\n",
    "            best_auc = 0\n",
    "            counter = 0\n",
    "\n",
    "            for epoch in range(20):\n",
    "                mlp.train()\n",
    "                for xb, yb in train_loader:\n",
    "                    xb, yb = xb.to(device), yb.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    loss = loss_function(mlp(xb), yb)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                mlp.eval()\n",
    "                all_probs, all_targets = [], []\n",
    "                with torch.no_grad():\n",
    "                    for xb, yb in val_loader:\n",
    "                        xb = xb.to(device)\n",
    "                        probs = torch.softmax(mlp(xb), dim=1)[:, 1].cpu().numpy()\n",
    "                        all_probs.extend(probs)\n",
    "                        all_targets.extend(yb.numpy())\n",
    "\n",
    "                auc = roc_auc_score(all_targets, all_probs)\n",
    "                print(f\"Epoch {epoch+1} - AUC: {auc:.4f}\")\n",
    "\n",
    "                if auc > best_auc:\n",
    "                    best_auc = auc\n",
    "                    counter = 0\n",
    "                else:\n",
    "                    counter += 1\n",
    "                    if counter >= patience:\n",
    "                        print(\"Early stopping\")\n",
    "                        break\n",
    "\n",
    "            print(f\"AUC MLP final (fold {fold+1}): {best_auc:.4f}\")\n",
    "            y_pred = [1 if p > 0.5 else 0 for p in all_probs]\n",
    "            f1 = f1_score(all_targets, y_pred)\n",
    "            print(f\"F1-SCORE (fold {fold+1}): {f1:.4f}\")\n",
    "\n",
    "            fold_aucs.append(best_auc)\n",
    "            fold_f1s.append(f1)\n",
    "\n",
    "        print(f'\\nMean AUC over {n_folds} folds: {np.mean(fold_aucs):.4f}')\n",
    "        print(f'Mean F1-Score over {n_folds} folds: {np.mean(fold_f1s):.4f}')\n",
    "\n",
    "MAX_FREQ = original_max_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23af4df",
   "metadata": {},
   "source": [
    "### Preprocesamos los datos para darselos al modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cb0682",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_all_mel_spectrograms(audio_train_df)\n",
    "y = audio_train_df['label'].values\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=SEED, stratify=y)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(X_val_tensor, y_val_tensor), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ba9f23",
   "metadata": {},
   "source": [
    "### Entrenamos 3 clasificadores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee65cffb",
   "metadata": {},
   "source": [
    "### Entrenamos un MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35570fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | Train Loss: 0.6706 | Val Loss: 0.4166 | Val Acc: 81.48%\n",
      "Epoch 2/20 | Train Loss: 0.3778 | Val Loss: 0.3269 | Val Acc: 86.27%\n",
      "Epoch 3/20 | Train Loss: 0.3596 | Val Loss: 0.3289 | Val Acc: 86.12%\n",
      "Epoch 4/20 | Train Loss: 0.3492 | Val Loss: 0.3557 | Val Acc: 84.93%\n",
      "Epoch 5/20 | Train Loss: 0.3294 | Val Loss: 0.4452 | Val Acc: 80.63%\n",
      "Epoch 6/20 | Train Loss: 0.3317 | Val Loss: 0.2874 | Val Acc: 86.98%\n",
      "Epoch 7/20 | Train Loss: 0.3121 | Val Loss: 0.2880 | Val Acc: 86.33%\n",
      "Epoch 8/20 | Train Loss: 0.3248 | Val Loss: 0.3812 | Val Acc: 82.58%\n",
      "Epoch 9/20 | Train Loss: 0.2992 | Val Loss: 0.3841 | Val Acc: 85.20%\n",
      "Epoch 10/20 | Train Loss: 0.3172 | Val Loss: 0.3377 | Val Acc: 84.45%\n",
      "Epoch 11/20 | Train Loss: 0.3094 | Val Loss: 0.4833 | Val Acc: 75.97%\n",
      "Epoch 12/20 | Train Loss: 0.3050 | Val Loss: 0.3261 | Val Acc: 83.90%\n",
      "Epoch 13/20 | Train Loss: 0.2850 | Val Loss: 0.4376 | Val Acc: 78.58%\n",
      "Epoch 14/20 | Train Loss: 0.2822 | Val Loss: 0.2885 | Val Acc: 87.30%\n",
      "Epoch 15/20 | Train Loss: 0.2817 | Val Loss: 0.2759 | Val Acc: 87.65%\n",
      "Epoch 16/20 | Train Loss: 0.3049 | Val Loss: 0.3036 | Val Acc: 85.45%\n",
      "Epoch 17/20 | Train Loss: 0.2801 | Val Loss: 0.3282 | Val Acc: 83.45%\n",
      "Epoch 18/20 | Train Loss: 0.2699 | Val Loss: 0.2815 | Val Acc: 86.43%\n",
      "Epoch 19/20 | Train Loss: 0.2808 | Val Loss: 0.3006 | Val Acc: 86.45%\n",
      "Epoch 20/20 | Train Loss: 0.2929 | Val Loss: 0.2957 | Val Acc: 87.02%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.6705507481892904,\n",
       "  0.37775769011179605,\n",
       "  0.3595704129536947,\n",
       "  0.3492476155757904,\n",
       "  0.3293753337065379,\n",
       "  0.33165173610051474,\n",
       "  0.3120691639582316,\n",
       "  0.3248308207988739,\n",
       "  0.2992423581282298,\n",
       "  0.3171571095784505,\n",
       "  0.3093904614448547,\n",
       "  0.3049719510873159,\n",
       "  0.28495409186681114,\n",
       "  0.2821574071248372,\n",
       "  0.2817471984227498,\n",
       "  0.304918466647466,\n",
       "  0.2801275690793991,\n",
       "  0.2699434053897858,\n",
       "  0.28079128901163736,\n",
       "  0.29293084239959716],\n",
       " [0.41662143023808795,\n",
       "  0.32686042062441506,\n",
       "  0.32888319150606793,\n",
       "  0.3556703697045644,\n",
       "  0.44518155113855995,\n",
       "  0.28738146352767946,\n",
       "  0.28802998026212057,\n",
       "  0.3812123747666677,\n",
       "  0.3840799209276835,\n",
       "  0.3377477540969849,\n",
       "  0.483326060851415,\n",
       "  0.3260912790298462,\n",
       "  0.4375786116123199,\n",
       "  0.2884549664656321,\n",
       "  0.27585036953290304,\n",
       "  0.30355821665128074,\n",
       "  0.32824550183614093,\n",
       "  0.28150105992952984,\n",
       "  0.3005807506243388,\n",
       "  0.29569728684425356])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_torch = MLP(X_train.shape[1])\n",
    "mlp_torch.to(device)\n",
    "\n",
    "train_losses, val_losses = mlp_torch.train_model(train_loader, val_loader, epochs=20, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e348bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | Train Loss: 0.2821 | Val Loss: 0.3876 | Val Acc: 83.40%\n",
      "Epoch 2/20 | Train Loss: 0.2788 | Val Loss: 0.2878 | Val Acc: 87.33%\n",
      "Epoch 3/20 | Train Loss: 0.2871 | Val Loss: 0.3928 | Val Acc: 79.98%\n",
      "Epoch 4/20 | Train Loss: 0.2708 | Val Loss: 0.3997 | Val Acc: 81.23%\n",
      "Epoch 5/20 | Train Loss: 0.2734 | Val Loss: 0.2613 | Val Acc: 86.30%\n",
      "Epoch 6/20 | Train Loss: 0.2631 | Val Loss: 0.3144 | Val Acc: 85.23%\n",
      "Epoch 7/20 | Train Loss: 0.2708 | Val Loss: 0.2925 | Val Acc: 87.62%\n",
      "Epoch 8/20 | Train Loss: 0.2753 | Val Loss: 0.2575 | Val Acc: 87.38%\n",
      "Epoch 9/20 | Train Loss: 0.2606 | Val Loss: 0.2787 | Val Acc: 87.88%\n",
      "Epoch 10/20 | Train Loss: 0.2619 | Val Loss: 0.3044 | Val Acc: 86.40%\n",
      "Epoch 11/20 | Train Loss: 0.2562 | Val Loss: 0.2742 | Val Acc: 88.13%\n",
      "Epoch 12/20 | Train Loss: 0.2610 | Val Loss: 0.2792 | Val Acc: 87.00%\n",
      "Epoch 13/20 | Train Loss: 0.2458 | Val Loss: 0.3055 | Val Acc: 86.02%\n",
      "Epoch 14/20 | Train Loss: 0.2515 | Val Loss: 0.3223 | Val Acc: 85.93%\n",
      "Epoch 15/20 | Train Loss: 0.2557 | Val Loss: 0.3950 | Val Acc: 80.18%\n",
      "Epoch 16/20 | Train Loss: 0.2498 | Val Loss: 0.3278 | Val Acc: 86.88%\n",
      "Epoch 17/20 | Train Loss: 0.2467 | Val Loss: 0.3288 | Val Acc: 83.70%\n",
      "Epoch 18/20 | Train Loss: 0.2608 | Val Loss: 0.2812 | Val Acc: 87.67%\n",
      "Epoch 19/20 | Train Loss: 0.2471 | Val Loss: 0.3080 | Val Acc: 87.85%\n",
      "Epoch 20/20 | Train Loss: 0.2616 | Val Loss: 0.2865 | Val Acc: 87.73%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# poner esto adentro del modelo como plot_learning_curves\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e11e15",
   "metadata": {},
   "source": [
    "### Pasamos los tensores a numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c052b588",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_np = X_train_tensor.numpy()\n",
    "y_train_np = y_train_tensor.numpy()\n",
    "X_val_np = X_val_tensor.numpy()\n",
    "y_val_np = y_val_tensor.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f9bc49",
   "metadata": {},
   "source": [
    "### Entrenamos un Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc51c93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf_model = train_random_forest(X_train_np, y_train_np, X_val_np, y_val_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd90ed4",
   "metadata": {},
   "source": [
    "### Entrenamos un Gradient Boosting\n",
    "cambiar a xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832e1f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_model = train_gradient_boosting(X_train_np, y_train_np, X_val_np, y_val_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1e78cf",
   "metadata": {},
   "source": [
    "### Visualizamos las curvas ROC de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d55d384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. MLP - predicción de probabilidades\n",
    "mlp_torch.eval()\n",
    "mlp_probs = []\n",
    "with torch.no_grad():\n",
    "    for xb, _ in val_loader:\n",
    "        xb = xb.to(device)\n",
    "        outputs = mlp_torch(xb)\n",
    "        probs = F.softmax(outputs, dim=1)[:, 1]  # clase positiva\n",
    "        mlp_probs.extend(probs.cpu().numpy())\n",
    "mlp_probs = np.array(mlp_probs)\n",
    "mlp_auc = roc_auc_score(y_val_np, mlp_probs)\n",
    "fpr_mlp, tpr_mlp, _ = roc_curve(y_val_np, mlp_probs)\n",
    "\n",
    "# 2. Random Forest\n",
    "rf_probs = rf_model.predict_proba(X_val_np)[:, 1]\n",
    "rf_auc = roc_auc_score(y_val_np, rf_probs)\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_val_np, rf_probs)\n",
    "\n",
    "# 3. Gradient Boosting\n",
    "gb_probs = gb_model.predict_proba(X_val_np)[:, 1]\n",
    "gb_auc = roc_auc_score(y_val_np, gb_probs)\n",
    "fpr_gb, tpr_gb, _ = roc_curve(y_val_np, gb_probs)\n",
    "\n",
    "# 4. Plot all ROC curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_mlp, tpr_mlp, label=f'MLP (AUC = {mlp_auc:.3f})')\n",
    "plt.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {rf_auc:.3f})')\n",
    "plt.plot(fpr_gb, tpr_gb, label=f'Gradient Boosting (AUC = {gb_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=0.8)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b712da5",
   "metadata": {},
   "source": [
    "### Entrenamos modelos generativos para data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9c64d1",
   "metadata": {},
   "source": [
    "#### Variational Autoencoder (VAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325a2a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARIATIONAL AUTOENCODER MODEL\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim=32):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.fc_mu = nn.Linear(128, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(128, latent_dim)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        return self.fc_mu(h), self.fc_logvar(h)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x_hat = self.decode(z)\n",
    "        return x_hat, mu, logvar\n",
    "\n",
    "    def loss(self, x, x_hat, mu, logvar):\n",
    "        recon_loss = nn.functional.mse_loss(x_hat, x, reduction='mean')\n",
    "        kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        return recon_loss + kl_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b54419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENTO [ NO BORRAR ]\n",
    "\n",
    "# Preparo los espectrogramas para enchufarselos al vae\n",
    "#   - grafico 5 muestras pre y post normalizar\n",
    "print(audio_df)\n",
    "\n",
    "original_spec_samples = []\n",
    "normalized_samples = []\n",
    "denormalized_samples = []\n",
    " \n",
    "global_min, global_max = compute_global_min_max(audio_df)\n",
    "\n",
    "whale_audio_samples = audio_df[audio_df['label'] == 1].sample(5)['audio']\n",
    "\n",
    "for sample in whale_audio_samples:\n",
    "    mel_spec = get_melspectrogram(sample)\n",
    "    original_spec_samples.append(mel_spec)\n",
    "\n",
    "    normalized_mel_spec = normalize_spectrogram(mel_spec, global_min, global_max)\n",
    "    normalized_samples.append(normalized_mel_spec)\n",
    "\n",
    "    denormalized_mel_spec = denormalize_spectrogram(normalized_mel_spec, global_min, global_max)\n",
    "    denormalized_samples.append(denormalized_mel_spec)\n",
    "\n",
    "fig, axes = plt.subplots(3, 5, figsize=(18, 8))\n",
    "\n",
    "for i in range(5):\n",
    "    # Original spectrogram\n",
    "    img0 = librosa.display.specshow(original_spec_samples[i], sr=SR, hop_length=HOP_LENGTH, ax=axes[0, i], x_axis='time', y_axis='hz', cmap='magma', fmax=MAX_FREQ)\n",
    "    axes[0, i].set_title(f'Original {i+1}')\n",
    "    axes[0, i].set_xticks([])\n",
    "    axes[0, i].set_yticks([])\n",
    "\n",
    "    # Normalized spectrogram\n",
    "    img1 = librosa.display.specshow(normalized_samples[i], sr=SR, hop_length=HOP_LENGTH, ax=axes[1, i], x_axis='time', y_axis='hz', cmap='magma', fmax=MAX_FREQ)\n",
    "    axes[1, i].set_title(f'Normalized {i+1}')\n",
    "    axes[1, i].set_xticks([])\n",
    "    axes[1, i].set_yticks([])\n",
    "\n",
    "    # Denormalized spectrogram\n",
    "    img2 = librosa.display.specshow(denormalized_samples[i], sr=SR, hop_length=HOP_LENGTH, ax=axes[2, i], x_axis='time', y_axis='hz', cmap='magma', fmax=MAX_FREQ)\n",
    "    axes[2, i].set_title(f'Denormalized {i+1}')\n",
    "    axes[2, i].set_xticks([])\n",
    "    axes[2, i].set_yticks([])\n",
    "\n",
    "axes[0, 0].set_ylabel('Original')\n",
    "axes[1, 0].set_ylabel('Normalized')\n",
    "axes[2, 0].set_ylabel('Denormalized')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(original_spec_samples[-1])\n",
    "print(normalized_samples[-1])\n",
    "print(denormalized_samples[-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1872b493",
   "metadata": {},
   "source": [
    "### Obtenemos los espectrogramas de todos los audios y los normalizamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe5bb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_specs = []\n",
    "for whale_audio in audio_df[audio_df['label'] == 1]['audio']:\n",
    "    mel = get_melspectrogram(whale_audio)\n",
    "    mel_norm = normalize_spectrogram(mel, global_min, global_max)\n",
    "    mel_specs.append(mel_norm.flatten())\n",
    "X = np.array(mel_specs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa43b8a",
   "metadata": {},
   "source": [
    "### Preparamos los datos para darselos al VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71abe63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(mel_specs)\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "train_loader = DataLoader(TensorDataset(X_tensor), batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba462ef",
   "metadata": {},
   "source": [
    "### Entrenamos el VAE y generamos muestras sintéticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85cfb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "vae = VAE(X.shape[1], latent_dim=32).to(device)  # Use all data, not X_train\n",
    "optimizer = optim.Adam(vae.parameters(), lr=1e-3)\n",
    "\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    vae.train()\n",
    "    total_loss = 0\n",
    "    for xb_tuple in train_loader:  # xb_tuple is a tuple (xb,)\n",
    "        xb = xb_tuple[0].to(device)\n",
    "        x_hat, mu, logvar = vae(xb)\n",
    "        loss = vae.loss(xb, x_hat, mu, logvar)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * xb.size(0)  # accumulate per sample\n",
    "    avg_loss = total_loss / len(train_loader.dataset)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e1d2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERO MUESTRAS SINTÉTICAS\n",
    "\n",
    "vae.eval()\n",
    "num_samples = 3\n",
    "latent_dim = 32  # Must match your VAE's latent_dim\n",
    "\n",
    "with torch.no_grad():\n",
    "    z = torch.randn(num_samples, latent_dim).to(device)\n",
    "    generated = vae.decode(z).cpu().numpy()\n",
    "\n",
    "fig, axes = plt.subplots(1, num_samples, figsize=(12, 4))\n",
    "\n",
    "for i in range(num_samples):\n",
    "    # Reshape to (N_MELS, time_steps)\n",
    "    spec_norm = generated[i].reshape((N_MELS, -1))\n",
    "    # Denormalize\n",
    "    spec = denormalize_spectrogram(spec_norm, global_min, global_max)\n",
    "    librosa.display.specshow(spec, sr=SR, hop_length=HOP_LENGTH, x_axis='time', y_axis='hz', cmap='magma', ax=axes[i], fmax=MAX_FREQ)\n",
    "    axes[i].set_title(f\"Synthetic Sample {i+1}\")\n",
    "    axes[i].set_ylim([0, MAX_FREQ])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b22521f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESCUCHAMOS LAS MUESTRAS SINTÉTICAS [ NO PROBE ESTO TODAVIA ]\n",
    "\n",
    "for i in range(num_samples):\n",
    "    spec_norm = generated[i].reshape((N_MELS, -1))\n",
    "    spec = denormalize_spectrogram(spec_norm, global_min, global_max)\n",
    "    # Invert dB to power\n",
    "    spec_power = librosa.db_to_power(spec)\n",
    "    # Invert Mel-spectrogram to waveform\n",
    "    audio = librosa.feature.inverse.mel_to_audio(\n",
    "        spec_power, \n",
    "        sr=SR, \n",
    "        n_fft=N_FFT, \n",
    "        hop_length=HOP_LENGTH, \n",
    "        n_iter=32, \n",
    "        fmax=MAX_FREQ\n",
    "    )\n",
    "    print(f\"Synthetic Sample {i+1}:\")\n",
    "    display(Audio(audio, rate=SR*1.5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c488022",
   "metadata": {},
   "source": [
    "### Buscamos hiperparámetros óptimos para el VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560f3c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BÚSQUEDA DE HIPERPARÁMETROS [ CAMBIAR PARA QUE SE PUEDA PROBAR DISTINTAS ARQUITECTURAS ]\n",
    "\n",
    "def train_vae(X, latent_dim, lr, epochs, batch_size, device):\n",
    "    vae = VAE(X.shape[1], latent_dim=latent_dim).to(device)\n",
    "    optimizer = optim.Adam(vae.parameters(), lr=lr)\n",
    "    dataset = TensorDataset(torch.tensor(X, dtype=torch.float32))\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    vae.train()\n",
    "    for epoch in range(epochs):\n",
    "        for xb_tuple in loader:\n",
    "            xb = xb_tuple[0].to(device)\n",
    "            x_hat, mu, logvar = vae(xb)\n",
    "            loss = vae.loss(xb, x_hat, mu, logvar)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return vae\n",
    "\n",
    "def evaluate_vae(vae, X, device):\n",
    "    vae.eval()\n",
    "    dataset = TensorDataset(torch.tensor(X, dtype=torch.float32))\n",
    "    loader = DataLoader(dataset, batch_size=128)\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for xb_tuple in loader:\n",
    "            xb = xb_tuple[0].to(device)\n",
    "            x_hat, mu, logvar = vae(xb)\n",
    "            loss = vae.loss(xb, x_hat, mu, logvar)\n",
    "            total_loss += loss.item() * xb.size(0)\n",
    "    return total_loss / len(dataset)\n",
    "\n",
    "# Example grid\n",
    "param_grid = {\n",
    "    'latent_dim': [8, 16, 32],\n",
    "    'lr': [1e-3, 5e-4],\n",
    "    'epochs': [20, 40],\n",
    "    'batch_size': [64]\n",
    "}\n",
    "\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=SEED)\n",
    "results = []\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    val_losses = []\n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        vae = train_vae(X_train, **params, device=device)\n",
    "        val_loss = evaluate_vae(vae, X_val, device=device)\n",
    "        val_losses.append(val_loss)\n",
    "    avg_loss = np.mean(val_losses)\n",
    "    print(f\"Params: {params}, Avg Val Loss: {avg_loss:.4f}\")\n",
    "    results.append((params, avg_loss))\n",
    "\n",
    "# Find best params\n",
    "best_params = min(results, key=lambda x: x[1])\n",
    "print(\"Best params:\", best_params[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74451cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Visualización con PCA\n",
    "# --------------------------\n",
    "vae.eval()\n",
    "all_mu = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb, yb in val_loader:\n",
    "        xb = xb.to(device)\n",
    "        mu, _ = vae.encode(xb)\n",
    "        all_mu.append(mu.cpu().numpy())\n",
    "        all_labels.append(yb.numpy())\n",
    "\n",
    "all_mu = np.concatenate(all_mu, axis=0)\n",
    "all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "z_pca = pca.fit_transform(all_mu)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(z_pca[:, 0], z_pca[:, 1], c=all_labels, cmap='coolwarm', alpha=0.7)\n",
    "plt.title(\"VAE Latent Space (PCA)\")\n",
    "plt.xlabel(\"PC 1\")\n",
    "plt.ylabel(\"PC 2\")\n",
    "plt.colorbar(scatter, label=\"Clase\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15179693",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=SEED)\n",
    "z_tsne = tsne.fit_transform(all_mu)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(z_tsne[:, 0], z_tsne[:, 1], c=all_labels, cmap='coolwarm', alpha=0.7)\n",
    "plt.title(\"VAE Latent Space (t-SNE)\")\n",
    "plt.xlabel(\"t-SNE 1\")\n",
    "plt.ylabel(\"t-SNE 2\")\n",
    "plt.colorbar(scatter, label=\"Clase\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa945e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === FUNCIONES PROPIAS REQUERIDAS ===\n",
    "# - get_melspectrogram(audio)\n",
    "# - normalize_spectrogram(mel, global_min, global_max)\n",
    "\n",
    "# === PREPROCESADO ===\n",
    "mel_specs_ballenas = []\n",
    "mel_specs_no_ballenas = []\n",
    "\n",
    "for _, row in audio_df.iterrows():\n",
    "    mel = get_melspectrogram(row['audio'])  # audio: waveform\n",
    "    mel_norm = normalize_spectrogram(mel, global_min, global_max)\n",
    "    mel_flat = mel_norm.flatten()\n",
    "\n",
    "    if row['label'] == 1:\n",
    "        mel_specs_ballenas.append(mel_flat)\n",
    "    else:\n",
    "        mel_specs_no_ballenas.append(mel_flat)\n",
    "\n",
    "# Convertimos a arrays\n",
    "X_ballenas     = np.array(mel_specs_ballenas)  # (N1, N_MELS * T)\n",
    "X_no_ballenas  = np.array(mel_specs_no_ballenas)  # (N2, N_MELS * T)\n",
    "\n",
    "# Unimos todo\n",
    "X_total = np.vstack([X_ballenas, X_no_ballenas])  # (N1+N2, ...)\n",
    "y_total = np.array([1]*len(X_ballenas) + [0]*len(X_no_ballenas))\n",
    "\n",
    "# Para PyTorch\n",
    "X_tensor_total = torch.tensor(X_total, dtype=torch.float32)\n",
    "y_tensor_total = torch.tensor(y_total, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "# Para VAE individual (solo ballenas)\n",
    "X_tensor_ballenas = torch.tensor(X_ballenas, dtype=torch.float32)\n",
    "train_loader_ballenas = DataLoader(TensorDataset(X_tensor_ballenas), batch_size=128, shuffle=True)\n",
    "\n",
    "# Para CVAE (todo con labels)\n",
    "train_loader_total = DataLoader(TensorDataset(X_tensor_total, y_tensor_total), batch_size=128, shuffle=True)\n",
    "\n",
    "\n",
    "class CVAE(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim=32, cond_dim=1):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim + cond_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(128, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(128, latent_dim)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim + cond_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def encode(self, x, y):\n",
    "        x_in = torch.cat([x, y], dim=1)\n",
    "        h = self.encoder(x_in)\n",
    "        return self.fc_mu(h), self.fc_logvar(h)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z, y):\n",
    "        z_in = torch.cat([z, y], dim=1)\n",
    "        return self.decoder(z_in)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        mu, logvar = self.encode(x, y)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x_hat = self.decode(z, y)\n",
    "        return x_hat, mu, logvar\n",
    "\n",
    "    def loss(self, x, x_hat, mu, logvar):\n",
    "        recon = nn.functional.mse_loss(x_hat, x, reduction='mean')\n",
    "        kl = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        return recon + kl\n",
    "\n",
    "# Preparar datos\n",
    "X_tensor = torch.tensor(X_total, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y_total.reshape(-1, 1), dtype=torch.float32)\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "loader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "cvae = CVAE(X_total.shape[1], latent_dim=32).to(device)\n",
    "optimizer = optim.Adam(cvae.parameters(), lr=1e-3)\n",
    "\n",
    "# Entrenar\n",
    "for epoch in range(50):\n",
    "    cvae.train()\n",
    "    total_loss = 0\n",
    "    for xb, yb in loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        x_hat, mu, logvar = cvae(xb, yb)\n",
    "        loss = cvae.loss(xb, x_hat, mu, logvar)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "    print(f\"[CVAE] Epoch {epoch+1}, Loss: {total_loss / len(loader.dataset):.4f}\")\n",
    "\n",
    "\n",
    "vae_ballena = VAE(X_ballenas.shape[1], latent_dim=32).to(device)\n",
    "vae_noballena = VAE(X_no_ballenas.shape[1], latent_dim=32).to(device)\n",
    "\n",
    "def train_vae(vae, X_data):\n",
    "    loader = DataLoader(TensorDataset(torch.tensor(X_data, dtype=torch.float32)), batch_size=128, shuffle=True)\n",
    "    optim_vae = optim.Adam(vae.parameters(), lr=1e-3)\n",
    "    for epoch in range(50):\n",
    "        vae.train()\n",
    "        total_loss = 0\n",
    "        for (xb,) in loader:\n",
    "            xb = xb.to(device)\n",
    "            x_hat, mu, logvar = vae(xb)\n",
    "            loss = vae.loss(xb, x_hat, mu, logvar)\n",
    "            optim_vae.zero_grad()\n",
    "            loss.backward()\n",
    "            optim_vae.step()\n",
    "            total_loss += loss.item() * xb.size(0)\n",
    "        print(f\"[VAE {'ballena' if vae == vae_ballena else 'no-ballena'}] Epoch {epoch+1}, Loss: {total_loss / len(loader.dataset):.4f}\")\n",
    "\n",
    "train_vae(vae_ballena, X_ballenas)\n",
    "train_vae(vae_noballena, X_no_ballenas)\n",
    "\n",
    "def get_latent_mu(vae, X, device):\n",
    "    vae.eval()\n",
    "    mu_list = []\n",
    "    loader = DataLoader(torch.tensor(X, dtype=torch.float32), batch_size=128)\n",
    "    with torch.no_grad():\n",
    "        for xb in loader:\n",
    "            xb = xb.to(device)\n",
    "            mu, _ = vae.encode(xb)\n",
    "            mu_list.append(mu.cpu().numpy())\n",
    "    return np.vstack(mu_list)\n",
    "\n",
    "# CVAE: usar label como condición\n",
    "X_tensor = torch.tensor(X_total, dtype=torch.float32).to(device)\n",
    "y_tensor = torch.tensor(y_total.reshape(-1, 1), dtype=torch.float32).to(device)\n",
    "cvae.eval()\n",
    "with torch.no_grad():\n",
    "    mu_cvae, _ = cvae.encode(X_tensor, y_tensor)\n",
    "    mu_cvae = mu_cvae.cpu().numpy()\n",
    "\n",
    "# VAE individual\n",
    "mu_ballena = get_latent_mu(vae_ballena, X_ballenas, device)\n",
    "mu_noballena = get_latent_mu(vae_noballena, X_no_ballenas, device)\n",
    "\n",
    "# Unimos y visualizamos\n",
    "mu_2vae = np.vstack([mu_ballena, mu_noballena])\n",
    "y_2vae = np.array([1]*len(mu_ballena) + [0]*len(mu_noballena))\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_latent(z, labels, title):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    scatter = plt.scatter(z[:, 0], z[:, 1], c=labels, cmap='coolwarm', alpha=0.7)\n",
    "    plt.colorbar(scatter, label=\"Clase\")\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# PCA y t-SNE para ambos métodos\n",
    "plot_latent(PCA(2).fit_transform(mu_cvae), y_total, \"CVAE Latent Space (PCA)\")\n",
    "plot_latent(TSNE(2, random_state=42).fit_transform(mu_cvae), y_total, \"CVAE Latent Space (t-SNE)\")\n",
    "\n",
    "plot_latent(PCA(2).fit_transform(mu_2vae), y_2vae, \"Dos VAEs Latent Space (PCA)\")\n",
    "plot_latent(TSNE(2, random_state=42).fit_transform(mu_2vae), y_2vae, \"Dos VAEs Latent Space (t-SNE)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d283d1",
   "metadata": {},
   "source": [
    "### Entrenamos un Generative Adversarial Network (GAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778bba16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAN\n",
    "\n",
    "# GAN parameters\n",
    "latent_dim = 32\n",
    "input_dim = X.shape[1]  # Flattened mel spectrogram size\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, output_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, z):\n",
    "        return self.model(z)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# --- Training Loop with Sample Saving ---\n",
    "sample_dir = \"gan_samples\"\n",
    "os.makedirs(sample_dir, exist_ok=True)\n",
    "save_every = 10  # Save every N epochs\n",
    "\n",
    "generator = Generator(latent_dim, input_dim).to(device)\n",
    "discriminator = Discriminator(input_dim).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=1e-4, betas=(0.5, 0.999))\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=1e-4, betas=(0.5, 0.999))\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for xb_tuple in train_loader:\n",
    "        real_data = xb_tuple[0].to(device)\n",
    "        batch_size = real_data.size(0)\n",
    "\n",
    "        # Train Discriminator\n",
    "        z = torch.randn(batch_size, latent_dim, device=device)\n",
    "        fake_data = generator(z)\n",
    "        real_labels = torch.ones(batch_size, 1, device=device)\n",
    "        fake_labels = torch.zeros(batch_size, 1, device=device)\n",
    "\n",
    "        d_real = discriminator(real_data)\n",
    "        d_fake = discriminator(fake_data.detach())\n",
    "        d_loss_real = criterion(d_real, real_labels)\n",
    "        d_loss_fake = criterion(d_fake, fake_labels)\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "\n",
    "        d_optimizer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "\n",
    "        # Train Generator\n",
    "        z = torch.randn(batch_size, latent_dim, device=device)\n",
    "        fake_data = generator(z)\n",
    "        d_fake = discriminator(fake_data)\n",
    "        g_loss = criterion(d_fake, real_labels)\n",
    "\n",
    "        g_optimizer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | D Loss: {d_loss.item():.4f} | G Loss: {g_loss.item():.4f}\")\n",
    "\n",
    "    # --- Save generated samples every N epochs ---\n",
    "    if (epoch + 1) % save_every == 0 or epoch == 0:\n",
    "        generator.eval()\n",
    "        with torch.no_grad():\n",
    "            z = torch.randn(3, latent_dim, device=device)\n",
    "            samples = generator(z).cpu().numpy()\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "        for i in range(3):\n",
    "            spec_norm = samples[i].reshape((N_MELS, -1))\n",
    "            spec = denormalize_spectrogram(spec_norm, global_min, global_max)\n",
    "            librosa.display.specshow(spec, sr=SR, hop_length=HOP_LENGTH, x_axis='time', y_axis='hz', cmap='magma', ax=axes[i], fmax=MAX_FREQ)\n",
    "            axes[i].set_title(f\"Sample {i+1} (Epoch {epoch+1})\")\n",
    "            axes[i].set_ylim([0, MAX_FREQ])\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{sample_dir}/epoch_{epoch+1}.png\")\n",
    "        plt.close()\n",
    "        generator.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251b0ebe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
